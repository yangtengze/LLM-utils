from utils.document_loader import CSVLoader, MDLoader, PDFLoader, TXTLoader
from typing import List, Dict
import yaml
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import requests
from tqdm import tqdm
from FlagEmbedding import FlagModel
import numpy as np
import json

class Rag:
    def __init__(self):
        """
        åˆå§‹åŒ– RAG æ¨¡å‹
        - æ”¯æŒå¤šç§æ–‡æ¡£åŠ è½½å™¨
        - ä½¿ç”¨ TF-IDF å‘é‡åŒ–å™¨è¿›è¡Œæ–‡æ¡£æ£€ç´¢
        """
        self.docs: List[str] = []  # å­˜å‚¨åŠ è½½çš„æ–‡æ¡£å†…å®¹
        self.config = self.load_config("configs")
        self.deivce = self.config['rag']['embedding_model']['device']
        self.embedding_model = FlagModel(self.config['rag']['embedding_model']['name'], 
                  query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
                  use_fp16=True,devices=self.deivce)
        # self.reranker_model = 
        self.doc_vectors: np.ndarray = None  # æ–‡æ¡£å‘é‡
    def load_config(self,config_name: str):
        config_path = Path("configs") / f"{config_name}.yaml"
        with open(config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
        
    def load_documents(self, file_paths: List[str]) -> None:
        """
        åŠ è½½å¤šç§æ ¼å¼çš„æ–‡æ¡£
        :param file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        with tqdm(file_paths, desc="ğŸ“ æ€»ä½“è¿›åº¦", position=0) as global_pbar:
            for file_path in global_pbar:
                global_pbar.set_postfix_str(f'æ­£åœ¨å¤„ç†ï¼š{Path(file_path).name}')
                if file_path.endswith('.csv'):
                    loader = CSVLoader()
                # elif file_path.endswith('.docx'):
                #     loader = docxLoader()
                elif file_path.endswith('.md'):
                    loader = MDLoader()
                elif file_path.endswith('.pdf'):
                    loader = PDFLoader()
                elif file_path.endswith('.txt'):
                    loader = TXTLoader()
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                # åŠ è½½æ–‡æ¡£å†…å®¹å¹¶ä¿ç•™è·¯å¾„ä¿¡æ¯
                chunks = loader.load(file_path)


                file_name = Path(file_path).name  # è·å–å¸¦æ‰©å±•åçš„æ–‡ä»¶å
                # ä¸ºå½“å‰æ–‡ä»¶åˆ›å»ºæ–‡æ¡£æ¡ç›®å’Œå‘é‡
                file_vectors = []
                for chunk in tqdm(chunks, 
                                desc=f"ğŸ“„ {file_name}",position=1):  # ä¿ç•™è¿›åº¦æ¡ç—•è¿¹
                    # å­˜å‚¨æ–‡æ¡£ä¿¡æ¯
                    self.docs.append({
                        "file_path": str(Path(file_path).absolute()),
                        "content": str(chunk)
                    })
                    # ç”Ÿæˆå¹¶å­˜å‚¨å‘é‡
                    file_vectors.append(self.embedding_model.encode(str(chunk)))
                # åˆå¹¶å‘é‡åˆ°æ€»æ•°ç»„
                if self.doc_vectors is None:
                    self.doc_vectors = np.array(file_vectors)
                else:
                    self.doc_vectors = np.vstack((self.doc_vectors, file_vectors))
    def retrieve_documents(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶è¿”å›å¸¦è·¯å¾„çš„ç»“æœ
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param top_k: è¿”å›ç»“æœæ•°é‡
        :return: åŒ…å«è·¯å¾„å’Œå†…å®¹çš„æ–‡æ¡£åˆ—è¡¨
        """
        if self.doc_vectors is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = self.embedding_model.encode(query).reshape(1, -1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_vector, self.doc_vectors).flatten()
        sorted_indices = np.argsort(similarities)[::-1][:top_k]

        return [{
            "score": similarities[i],
            "content": self.docs[i]["content"],
            "file_path": self.docs[i]["file_path"]
        } for i in sorted_indices]
    
    def generate_prompt(self, query: str, top_k: int = 3) -> str:
        """
        ç”Ÿæˆ RAG æç¤º
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param top_k: è¿”å›æœ€ç›¸å…³çš„ top_k æ–‡æ¡£
        :return: ç”Ÿæˆçš„æç¤ºæ–‡æœ¬
        """
        relevant_docs = self.retrieve_documents(query, top_k)
        prompt = f"ç”¨æˆ·æŸ¥è¯¢: {query}\n\nç›¸å…³æ–‡æ¡£:\n"
        for i, doc in enumerate(relevant_docs):
            prompt += f"""
            æ–‡æ¡£ {i+1} [æ¥è‡ª: {doc['file_path']}]:
            {doc['content']}
            ç›¸ä¼¼åº¦å¾—åˆ†: {doc['score']:.4f}\n\n
            """
        return prompt

    def generate_response(self, query: str) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆå“åº”
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: ç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        prompt = self.generate_prompt(query)
        print("[DEBUG] ç”Ÿæˆçš„æç¤º:\n", prompt)
        # è°ƒç”¨ç”Ÿæˆæ¨¡å‹ï¼ˆè¿™é‡Œç”¨ä¼ªä»£ç è¡¨ç¤ºï¼‰
        response = self._call_language_model(prompt)
        return response

    def _call_language_model(self, prompt: str) -> str:
        """
        è°ƒç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆå“åº”ï¼ˆä¼ªä»£ç ï¼‰
        :param prompt: æç¤ºæ–‡æœ¬
        :return: ç”Ÿæˆçš„å“åº”
        """
        # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„æ¨¡å‹è°ƒç”¨ï¼Œä¾‹å¦‚ OpenAI API æˆ–æœ¬åœ°æ¨¡å‹
        # ä¾‹å¦‚ï¼š
        # response = openai.Completion.create(prompt=prompt, ...)
        # return response.choices[0].text
        self.llm_model = self.config['ollama']['default_model']
        data = {
            "model": self.llm_model,
            "prompt": prompt,
            "stream": self.config['ollama']['stream'],
            "options": {
                "temperature": self.config['ollama']['temperature']
            },
        }
        url = self.config['ollama']['endpoint'] + '/api/generate'
        response = requests.post(url, json=json.dumps(data))
        return response
        # return f"åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå“åº”:\n{prompt}"

# # ç¤ºä¾‹ç”¨æ³•
# if __name__ == "__main__":
#     rag = Rag()
    
#     # åŠ è½½æ–‡æ¡£
#     rag.load_documents(['data/documents/data.csv','data/documents/test.txt'])
    
#     # ç”Ÿæˆå“åº”
#     query = "ä½ æ˜¯è°å•Šï¼Ÿä½ å«ä»€ä¹ˆï¼Ÿ"
#     response = rag.generate_response(query)
#     print(response)