from utils.document_loader import CSVLoader, MDLoader, PDFLoader, TXTLoader
from typing import List, Dict
import yaml
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import requests
from tqdm import tqdm
from FlagEmbedding import FlagModel
import numpy as np
import json
import os
import time
class Rag:
    def __init__(self):
        """
        åˆå§‹åŒ– RAG æ¨¡å‹
        - æ”¯æŒå¤šç§æ–‡æ¡£åŠ è½½å™¨
        - è‡ªåŠ¨åŠ è½½å·²ä¿å­˜çš„æ–‡æ¡£å’Œå‘é‡
        - æ”¯æŒå¢é‡æ·»åŠ æ–‡æ¡£
        """
        self.config = self.load_config("configs")

        persist_dir = self.config['rag']['vector_store']['index_path']
        self.persist_dir = Path(persist_dir)
        self.persist_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¶è‡ªåŠ¨åŠ è½½å·²æœ‰æ•°æ®
        self.docs = self._load_metadata()
        self.doc_vectors = self._load_vectors()

        self.device = self.config['rag']['embedding_model']['device']
        self.embedding_model = FlagModel(self.config['rag']['embedding_model']['name'], 
                  query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
                  use_fp16=True,devices=self.device)
        # self.reranker_model = 
    
    def load_config(self,config_name: str):
        config_path = Path("configs") / f"{config_name}.yaml"
        with open(config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def _get_vector_path(self) -> Path:
        """è·å–å‘é‡å­˜å‚¨è·¯å¾„"""
        return self.persist_dir / "doc_vectors.npy"

    def _get_metadata_path(self) -> Path:
        """è·å–å…ƒæ•°æ®å­˜å‚¨è·¯å¾„"""
        return self.persist_dir / "metadata.json"

    def _load_vectors(self) -> np.ndarray:
        """åŠ è½½å·²ä¿å­˜çš„å‘é‡"""
        vector_path = self._get_vector_path()
        if vector_path.exists():
            return np.load(vector_path)
        return None

    def _load_metadata(self) -> List[Dict]:
        """åŠ è½½å·²ä¿å­˜çš„å…ƒæ•°æ®"""
        metadata_path = self._get_metadata_path()
        if metadata_path.exists():
            with open(metadata_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return []

    def _save_data(self):
        """ä¿å­˜å½“å‰æ•°æ®åˆ°ç£ç›˜"""
        # ä¿å­˜å‘é‡
        if self.doc_vectors is not None:
            np.save(self._get_vector_path(), self.doc_vectors)
        
        # ä¿å­˜å…ƒæ•°æ®
        with open(self._get_metadata_path(), "w", encoding="utf-8") as f:
            json.dump(self.docs, f, ensure_ascii=False, indent=2)

        
    def load_documents(self, file_paths: List[str]) -> None:
        """
        åŠ è½½å¤šç§æ ¼å¼çš„æ–‡æ¡£ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        # è½¬æ¢æ‰€æœ‰è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
        abs_paths = [str(Path(fp).absolute()) for fp in file_paths]
        
        # è¿‡æ»¤å·²åŠ è½½æ–‡ä»¶ï¼ˆä½¿ç”¨é›†åˆæé«˜æŸ¥è¯¢æ•ˆç‡ï¼‰
        existing_files = {doc["file_path"] for doc in self.docs}
        new_files = [fp for fp in abs_paths if fp not in existing_files]
        
        if not new_files:
            print("æ‰€æœ‰æ–‡ä»¶å‡å·²åŠ è½½è¿‡")
            return

        try:
            # å°†numpyæ•°ç»„è½¬ä¸ºåˆ—è¡¨ä¾¿äºè¿½åŠ 
            if self.doc_vectors is not None:
                vectors = self.doc_vectors.tolist()
            else:
                vectors = []

            with tqdm(new_files, desc="ğŸ“ æ€»ä½“è¿›åº¦") as global_pbar:
                for file_path in global_pbar:
                    global_pbar.set_postfix_str(f'å¤„ç†ä¸­: {Path(file_path).name}')
                    
                    try:
                        # è·å–æ–‡ä»¶åŠ è½½å™¨
                        if file_path.endswith('.csv'):
                            loader = CSVLoader()
                        elif file_path.endswith('.md'):
                            loader = MDLoader()
                        elif file_path.endswith('.pdf'):
                            loader = PDFLoader()
                        elif file_path.endswith('.txt'):
                            loader = TXTLoader()
                        else:
                            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")

                        # åŠ è½½æ–‡æ¡£å†…å®¹
                        chunks = loader.load(file_path)
                        
                        # å¤„ç†æ–‡æ¡£å—
                        file_vectors = []
                        for chunk in tqdm(chunks, desc=f"ğŸ“„ {Path(file_path).name}", leave=True):
                            # å­˜å‚¨å…ƒæ•°æ®
                            self.docs.append({
                                "file_path": file_path,
                                "content": str(chunk),
                                "timestamp": time.time()  # æ·»åŠ æ—¶é—´æˆ³ç”¨äºç‰ˆæœ¬æ§åˆ¶
                            })
                            # ç”Ÿæˆå‘é‡
                            file_vectors.append(self.embedding_model.encode(str(chunk)))
                        
                        # è¿½åŠ å‘é‡
                        vectors.extend(file_vectors)

                    except Exception as e:
                        print(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}")
                        continue

            # ç»Ÿä¸€è½¬æ¢ä¸ºnumpyæ•°ç»„
            self.doc_vectors = np.array(vectors)
            
        finally:
            # æœ€ç»ˆä¿å­˜æ•°æ®
            self._save_data()

    def reset(self):
        """é‡ç½®æ‰€æœ‰å­˜å‚¨æ•°æ®"""
        self.doc_vectors = None
        self.docs = []
        if self._get_vector_path().exists():
            os.remove(self._get_vector_path())
        if self._get_metadata_path().exists():
            os.remove(self._get_metadata_path())
    def retrieve_documents(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶è¿”å›å¸¦è·¯å¾„çš„ç»“æœ
        :param query: æŸ¥è¯¢æ–‡æœ¬
        :param top_k: è¿”å›ç»“æœæ•°é‡
        :return: åŒ…å«è·¯å¾„å’Œå†…å®¹çš„æ–‡æ¡£åˆ—è¡¨
        """
        if self.doc_vectors is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = self.embedding_model.encode(query).reshape(1, -1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_vector, self.doc_vectors).flatten()
        sorted_indices = np.argsort(similarities)[::-1][:top_k]

        return [{
            "score": similarities[i],
            "content": self.docs[i]["content"],
            "file_path": self.docs[i]["file_path"]
        } for i in sorted_indices]
    
    def generate_prompt(self, query: str, top_k: int = 3) -> str:
        """
        ç”Ÿæˆ RAG æç¤º
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param top_k: è¿”å›æœ€ç›¸å…³çš„ top_k æ–‡æ¡£
        :return: ç”Ÿæˆçš„æç¤ºæ–‡æœ¬
        """
        relevant_docs = self.retrieve_documents(query, top_k)
        prompt = f"ç”¨æˆ·æŸ¥è¯¢: {query}\n\nç›¸å…³æ–‡æ¡£:\n"
        for i, doc in enumerate(relevant_docs):
            prompt += f"""
            æ–‡æ¡£ {i+1} [æ¥è‡ª: {doc['file_path']}]:
            {doc['content']}
            ç›¸ä¼¼åº¦å¾—åˆ†: {doc['score']:.4f}\n\n
            """
        return prompt

    def generate_response(self, query: str) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆå“åº”
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: ç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        prompt = self.generate_prompt(query)
        print("[DEBUG] ç”Ÿæˆçš„æç¤º:\n", prompt)
        # è°ƒç”¨ç”Ÿæˆæ¨¡å‹ï¼ˆè¿™é‡Œç”¨ä¼ªä»£ç è¡¨ç¤ºï¼‰
        response = self._call_language_model(prompt)
        return response

    def _call_language_model(self, prompt: str) -> str:
        """
        è°ƒç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆå“åº”ï¼ˆä¼ªä»£ç ï¼‰
        :param prompt: æç¤ºæ–‡æœ¬
        :return: ç”Ÿæˆçš„å“åº”
        """
        # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„æ¨¡å‹è°ƒç”¨ï¼Œä¾‹å¦‚ OpenAI API æˆ–æœ¬åœ°æ¨¡å‹
        # ä¾‹å¦‚ï¼š
        # response = openai.Completion.create(prompt=prompt, ...)
        # return response.choices[0].text
        self.llm_model = self.config['ollama']['default_model']
        data = {
            "model": self.llm_model,
            "prompt": prompt,
            "stream": self.config['ollama']['stream'],
            "options": {
                "temperature": self.config['ollama']['temperature']
            },
        }
        url = self.config['ollama']['endpoint'] + '/api/generate'
        response = requests.post(url, json=json.dumps(data))
        return response
        # return f"åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå“åº”:\n{prompt}"

# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    rag = Rag()
    # åŠ è½½æ–‡æ¡£
    rag.load_documents(['data/documents/data.csv','data/documents/test.txt'])
    
    # ç”Ÿæˆå“åº”
    query = "ä½ æ˜¯è°å•Šï¼Ÿä½ å«ä»€ä¹ˆï¼Ÿ"
    response = rag.generate_response(query)
    print(response)